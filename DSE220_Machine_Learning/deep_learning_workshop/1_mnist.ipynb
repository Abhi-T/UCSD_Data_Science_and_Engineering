{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning: MNIST\n",
    "Supplemental files for the \"Deep Learning\" workshop, presented by the IDEA Student Center at UC San Diego.\n",
    "\n",
    "## Requirements\n",
    "- python 3.x\n",
    "- numpy\n",
    "- matplotlib\n",
    "- keras\n",
    "- tensorflow\n",
    "\n",
    "## Goals\n",
    "In this notebook, we'll compare the performance of \"classic\" Machine Learning methods and Deep Learning, as measured by the classification accuracy on the MNIST numerical digits data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is just a means of specifying layers/parameters vs. having to code from scratch in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load required functionality from keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as keras_backend\n",
    "\n",
    "# make the code compatible with both Python 2 and 3\n",
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) MNIST\n",
    "We'll be using the MNIST data set for evaluating different classification methods. MNIST is a large database of handwritten digits (0-9) that is commonly used for training and benchmarking binary classification models.\n",
    "\n",
    "Here's a preview of some of the MNIST samples, where each sample has a corresponding label (0-9):\n",
    "<img src=\"mnist_samples.png\" width=\"75%\">\n",
    "\n",
    "\n",
    "Before we create any models, we'll start by loading the MNIST data and viewing some sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download MNIST data\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# split MNIST data into training and testing sets\n",
    "# - training: data used to learn the model parameters\n",
    "# - testing: a separate set that we will use to validate our model performance\n",
    "#\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras packaged did the \"grunt work\" for us, but it's still a good idea to check the results (i.e. not just assume everything is fine). First, let's check out some meta data about the data sets and verify that they are what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# check the dimensions of the data\n",
    "print( X_train.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the dimensions tell us about MNIST? To better answer this, let's try viewing some of the MNIST images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANBEX4gKMIPBEX4gaAIPxAU4QeC+n8DZI6NXofNrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ad80a97828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select an image\n",
    "img = X_train[0]\n",
    "\n",
    "# show the image\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice anything about the images? For example, how many pixels are in each image?\n",
    "\n",
    "Now that we can view the images, let's try also showing the true label alongside the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ad80bcc438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select one of the images and its corresponding label\n",
    "i = 1001\n",
    "img = X_train[i]\n",
    "label = y_train[i]\n",
    "\n",
    "# show the image and its label\n",
    "plt.imshow(img)\n",
    "plt.title(\"True label: %d\" % label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Logistic regression\n",
    "We'll start with a classic ML classification method (logistic regression) to get a baseline on performance.\n",
    "\n",
    "**NOTE:** There is abundance of implementations of logistic regression (in Python and other languages). We'll use Keras to implement logistic regression simply to stay consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move onto models, we should pre-process the MNIST data:\n",
    "1. reshape the MNIST images into 1D arrays (from 2D arrays)\n",
    "2. normalize the MNIST images\n",
    "3. convert the MNIST labels\n",
    "\n",
    "Run the code below as-is to pre-process the MNIST data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data again (to be safe)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape the data: (n_samples, 28, 28) => (n_samples, 28*28)\n",
    "X_train = X_train.reshape(-1, 28 * 28)\n",
    "X_test = X_test.reshape(-1, 28 * 28)\n",
    "\n",
    "# convert data type and normalize the values (8-bit = 256 = 0...255)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# convert the class labels to 10-dimensional class arrays:\n",
    "# - before: y_train = (n_samples, )\n",
    "# - after: Y_train = (n_samples, 10)\n",
    "#\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Orysya\\Anaconda\\envs\\deeplearning\\lib\\site-packages\\keras\\models.py:834: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s - loss: 1.2678 - acc: 0.7142 - val_loss: 0.8052 - val_acc: 0.8298\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s - loss: 0.7112 - acc: 0.8424 - val_loss: 0.6073 - val_acc: 0.8611\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.5860 - acc: 0.8599 - val_loss: 0.5274 - val_acc: 0.8728\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.5256 - acc: 0.8689 - val_loss: 0.4819 - val_acc: 0.8812\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.4885 - acc: 0.8748 - val_loss: 0.4528 - val_acc: 0.8848\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s - loss: 0.4628 - acc: 0.8798 - val_loss: 0.4311 - val_acc: 0.8874\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s - loss: 0.4437 - acc: 0.8837 - val_loss: 0.4150 - val_acc: 0.8923\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.4288 - acc: 0.8867 - val_loss: 0.4024 - val_acc: 0.8939\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.4169 - acc: 0.8890 - val_loss: 0.3916 - val_acc: 0.8964\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.4068 - acc: 0.8907 - val_loss: 0.3830 - val_acc: 0.8984\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3983 - acc: 0.8924 - val_loss: 0.3760 - val_acc: 0.8994\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s - loss: 0.3910 - acc: 0.8940 - val_loss: 0.3687 - val_acc: 0.9017\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.3845 - acc: 0.895 - 2s - loss: 0.3846 - acc: 0.8954 - val_loss: 0.3631 - val_acc: 0.9019\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s - loss: 0.3789 - acc: 0.8968 - val_loss: 0.3582 - val_acc: 0.9034\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3739 - acc: 0.8976 - val_loss: 0.3539 - val_acc: 0.9042\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3693 - acc: 0.8991 - val_loss: 0.3498 - val_acc: 0.9056\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3651 - acc: 0.9000 - val_loss: 0.3463 - val_acc: 0.9060\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3614 - acc: 0.9011 - val_loss: 0.3428 - val_acc: 0.9070\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3579 - acc: 0.9015 - val_loss: 0.3398 - val_acc: 0.9076\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3547 - acc: 0.9026 - val_loss: 0.3368 - val_acc: 0.9085\n",
      "Test score: 0.336833753192\n",
      "Test accuracy: 0.9085\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=28*28, activation='softmax')) # 10 inputs (digits 0-9), dense uses all layers\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])  #sgd -> stochastic gradient descent          \n",
    "\n",
    "# train the model on data\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=128, # how many images to look at together\n",
    "          nb_epoch=20,       # how many epochs to run before stopping\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test)\n",
    "         )\n",
    "\n",
    "# test the trained model on the testing set\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "\n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Accuracy is the fraction of correct classifications of numeric digits in the MNIST testing set (e.g. 0.9 = 90% accuracy on images the model has not seen yet).\n",
    "\n",
    "Let's look at a few results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ny2gcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ad80b8d8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select an image\n",
    "#i = 200 #correct classification\n",
    "i = 403 #incorrect classification\n",
    "img = X_test[i].reshape(28, 28)\n",
    "\n",
    "# prepare the image to be used in the model\n",
    "x = img.reshape(-1, 28*28)\n",
    "\n",
    "# get the model output\n",
    "model_label = np.argmax( model.predict(x) )\n",
    "\n",
    "# get the true label\n",
    "true_label = np.argmax(Y_test[i])\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title('True label: {0}, Model label: {1}'.format(true_label, model_label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Multilayer Perceptron (MLP)\n",
    "Next we'll try out a \"classic\" neural network model (i.e. not a deep neural network).\n",
    "\n",
    "A Multilayer Perceptron (aka an Artificial Neural Network) is made up of an input layer, one or more hidden layers, and an output layer:\n",
    "<img src=\"diagram_mlp.jpg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 19s - loss: 0.3362 - acc: 0.8969 - val_loss: 0.1254 - val_acc: 0.9625\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 21s - loss: 0.1618 - acc: 0.9520 - val_loss: 0.1004 - val_acc: 0.9702\n",
      "Test loss: 0.100385358164\n",
      "Test accuracy: 0.9702\n"
     ]
    }
   ],
   "source": [
    "# create the MLP model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "model.add(Dropout(0.5)) #randomly forgets certain things ie. 20% or 50% become forgotten for example\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# print a summary of the model topology\n",
    "#model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Discussion\n",
    "**Question 1:** How did the accuracy of the MLP model compare to the Logistic Regression model?\n",
    "\n",
    "**Question 2:** Can you identify any other differences between the MLP and Logistic Regression models? *Hint:* Was there a difference in the code complexity and/or training time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Exercises\n",
    "Try to see the effects of the training and network parameters:\n",
    "- learning rate\n",
    "- number of training epochs\n",
    "- batch size\n",
    "- size of the 1st hidden layer\n",
    "- size of the 2nd hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Convolutional Neural Network (CNN)\n",
    "Now let's try out first deep neural network: a Convolutional Neural Network (CNN).\n",
    "\n",
    "The CNN is made up of a few core layer types, which get stacked on top of each other:\n",
    "- convolutional layers (2D)\n",
    "- max pooling layers (2D)\n",
    "- fully connected (aka densely connected) layers (same type as in the MLP model)\n",
    "\n",
    "The idea is that by stacking the layers, the model is able to build up increasingly complex hierarchy of features. For example, the 1st layer may extract features corresponding to geometric primitives (e.g. lines and curves), which then feed into the next layer to form shapes (e.g. ellipsoids), and so on, until you have \"recognizable\" features (e.g. ears, faces and dogs).\n",
    "\n",
    "Here's a typical CNN:\n",
    "<img src=\"diagram_cnn.png\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to perform pre-processing on the MNIST data, but with a slight tweak from the previous examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data again (to be safe)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape the data based on what backend is in use (TensorFlow or Thean)\n",
    "if keras_backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(-1, 1, 28, 28)\n",
    "    X_test = X_test.reshape(-1, 1, 28, 28)\n",
    "else:\n",
    "    X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "    X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# convert data type and normalize the values (8-bit = 256 = 0...255)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# convert the class labels to 10-dimensional class arrays:\n",
    "# - before: y_train = (n_samples, )\n",
    "# - after: Y_train = (n_samples, 10)\n",
    "#\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 339s - loss: 0.3494 - acc: 0.8938 - val_loss: 0.0920 - val_acc: 0.9713\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 336s - loss: 0.1114 - acc: 0.9668 - val_loss: 0.0573 - val_acc: 0.9812\n",
      "Test loss: 0.0572557648972\n",
      "Test accuracy: 0.9812\n"
     ]
    }
   ],
   "source": [
    "# create the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)\n",
    "                ))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.1) Discussion\n",
    "**Question 1:** How did the accuracy of the CNN compare to the MLP and Logistic Regression models?\n",
    "\n",
    "**Question 2:** Can you identify any other differences between the three models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Exercises\n",
    "Just as with the MLP model, try changing the training and network parameters to improve performance of the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
